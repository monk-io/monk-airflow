---
namespace: airflow

airflow-common:
  metadata:
    name: Apache Airflow
    description: |
      Apache Airflow is an open-source platform used for creating, scheduling, and monitoring workflows.

      It allows users to define and execute complex workflows, which can include tasks such as data processing, machine learning, and ETL (extract, transform, load) processes.

      Airflow provides a web-based user interface for managing workflows, as well as a command-line interface for more advanced users. It also supports a wide range of integrations with other tools and services, such as databases, cloud platforms, and messaging systems.

      Airflow is highly scalable and can be deployed on-premises or in the cloud, making it a popular choice for data engineering and data science teams.
    website: https://airflow.apache.org/
    publisher: monk.io
    icon: https://airflow.apache.org/favicons/android-icon-192x192.png
    private: true
    version: 1.0
  connections:
    database:
      runnable: airflow/airflow-db
      service: db-svc
    redis:
      runnable: airflow/airflow-redis
      service: rds-svc
  variables:
    database_host:
      type: string
      value: <- connection-hostname("database")
    redis_host:
      type: string
      value: <- connection-hostname("redis")
    db_user:
      env: POSTGRES_USER
      value: <- $database_user default("airflow")
      type: string
    db_pass:
      env: POSTGRES_PASSWORD
      value: <- $database_password default("airflow")
      type: string
    db_name:
      env: POSTGRES_DB
      value: <- $database_name default("airflow")
      type: string
    airflow_core_executor:
      env: AIRFLOW__CORE__EXECUTOR
      type: string
      value: CeleryExecutor
    airflow_database_sql_alchemy_conn:
      env: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
      type: string
      value: <- "postgresql+psycopg2://" $db_user ":" $db_pass "@" $database_host "/" $db_name concat-all
    airflow_celery_result_backend:
      env: AIRFLOW__CELERY__RESULT_BACKEND
      type: string
      value: <- "db+postgresql://" $db_user ":" $db_pass "@" $database_host "/" $db_name concat-all
    airflow_celery_broker_url:
      env: AIRFLOW__CELERY__BROKER_URL
      type: string
      value: <- "redis://:@" $redis_host ":6379/0" concat-all
    airflow_core_fernet_key:
      env: AIRFLOW__CORE__FERNET_KEY
      type: string
      value: ''
    airflow_core_dags_are_paused_at_creation:
      env: AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION
      type: string
      value: true
    airflow_core_load_examples:
      env: AIRFLOW__CORE__LOAD_EXAMPLES
      type: string
      value: true
    airflow_api_auth_backends:
      env: AIRFLOW__API__AUTH_BACKENDS
      type: string
      value: airflow.api.auth.backend.basic_auth
    airflow_pip_additional_requirements:
      env: _PIP_ADDITIONAL_REQUIREMENTS
      type: string
      value: airflow.api.auth.backend.basic_auth
    web_server_port:
      env: WEB_SERVER_PORT
      type: int
      value: <- $webserver_port default(8080)
    airflow_uuid:
      env: AIRFLOW_UUID
      type: string
      value: 50000
  depends:
    wait-for:
      runnables:
        - airflow/airflow-redis
        - airflow/airflow-db

airflow-redis:
  defines: runnable
  metadata:
    name: Redis
    description: Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker.
    website: https://redis.io
    publisher: monk.io
    icon: https://cdn.icon-icons.com/icons2/2415/PNG/512/redis_original_wordmark_logo_icon_146369.png
    private: true
    version: 1.0
  containers:
    airflow-redis:
      image: redis:latest
  services:
    rds-svc:
      port: 6379
      container: airflow-redis
      protocol: tcp
      host-port: 6379

airflow-db:
  defines: runnable
  metadata:
    name: PostgreSQL
    description: PostgreSQL is a powerful, open source object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.
    website: https://www.postgresql.org
    publisher: monk.io
    icon: https://www.postgresql.org/media/img/about/press/elephant.png
    private: true
    version: 1.0
  variables:
    image-tag:
      type: string
      value: latest
    db_user:
      env: POSTGRES_USER
      value: <- $database_user default("airflow")
      type: string
    db_pass:
      env: POSTGRES_PASSWORD
      value: <- $database_password default("airflow")
      type: string
    db_name:
      env: POSTGRES_DB
      value: <- $database_name default("airflow")
      type: string
    db_trust:
      env: POSTGRES_HOST_AUTH_METHOD
      value: trust
  containers:
    postgres:
      image: postgres
      image-tag: <- `${image-tag}`
      paths:
        - <- `${monk-volume-path}/airflow/db_data:/var/lib/postgresql/data`
  services:
    db-svc:
      port: 5432
      container: postgres
      protocol: tcp
      host-port: 5432

airflow-webserver:
  defines: runnable
  inherits: airflow/airflow-common
  containers:
    airflow-webserver:
      user: 50000:0
      image: apache/airflow
      bash: airflow webserver
      ports:
        - 8080:8080
      paths:
        - <- `${monk-volume-path}/airflow/dags:/opt/airflow/dags`
        - <- `${monk-volume-path}/airflow/logs:/opt/airflow/logs`
        - <- `${monk-volume-path}/airflow/plugins:/opt/airflow/plugins`
  check:
    readiness:
      code:
        - curl
        - --fail
        - http://localhost:8080/health
      period: 10
      initialDelay: 10
      interval: 5
  services:
    webserver-svc:
      port: 8080
      container: airflow-webserver
      protocol: tcp
      host-port: 8080

airflow-scheduler:
  defines: runnable
  inherits: airflow/airflow-common
  containers:
    airflow-scheduler:
      user: 50000:0
      image: apache/airflow
      bash: airflow scheduler
      paths:
        - <- `${monk-volume-path}/airflow/dags:/opt/airflow/dags`
        - <- `${monk-volume-path}/airflow/logs:/opt/airflow/logs`
        - <- `${monk-volume-path}/airflow/plugins:/opt/airflow/plugins`
  check:
    readiness:
      code:
        - airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"
      period: 10
      initialDelay: 10
      interval: 5

airflow-worker:
  defines: runnable
  inherits: airflow/airflow-common
  variables:
    monk_dumb_init:
      env: DUMB_INIT_SETSID
      type: string
      value: 0
    monk_celery_broker_url:
      env: CELERY_BROKER_URL
      type: string
      value: <- `${airflow_celery_broker_url}`
  containers:
    airflow-worker:
      user: 50000:0
      image: apache/airflow
      bash: celery worker
      paths:
        - <- `${monk-volume-path}/airflow/dags:/opt/airflow/dags`
        - <- `${monk-volume-path}/airflow/logs:/opt/airflow/logs`
        - <- `${monk-volume-path}/airflow/plugins:/opt/airflow/plugins`
  check:
    readiness:
      code:
        - celery --app airflow.executors.celery_executor.app inspect ping -d "celery@$${HOSTNAME}"
      period: 10
      initialDelay: 10
      interval: 5

airflow-triggerer:
  defines: runnable
  inherits: airflow/airflow-common
  containers:
    airflow-triggerer:
      user: 50000:0
      image: apache/airflow
      bash: airflow triggerer
      paths:
        - <- `${monk-volume-path}/airflow/dags:/opt/airflow/dags`
        - <- `${monk-volume-path}/airflow/logs:/opt/airflow/logs`
        - <- `${monk-volume-path}/airflow/plugins:/opt/airflow/plugins`
  check:
    readiness:
      code:
        - airflow jobs check --job-type TriggererJob --hostname "$${HOSTNAME}"
      period: 10
      initialDelay: 10
      interval: 5

airflow-init:
  defines: runnable
  inherits: airflow/airflow-common
  variables:
    airflow_db_updare:
      env: _AIRFLOW_DB_UPGRADE
      type: string
      value: true
    airflow_www_user_create:
      env: _AIRFLOW_WWW_USER_CREATE
      type: string
      value: true
    airflow_www_user_username:
      env: _AIRFLOW_WWW_USER_USERNAME
      type: string
      value: <- $airflow_username default("airflow")
    airflow_www_user_password:
      env: _AIRFLOW_WWW_USER_PASSWORD
      type: string
      value: <- $airflow_password default("airflow")
    airflow_pip_additional_requirements:
      env: _PIP_ADDITIONAL_REQUIREMENTS
      type: string
      value: ''
  containers:
    airflow-init:
      user: 0:0
      image: apache/airflow
      bash: /opt/airflow/init.sh
      paths:
        - <- `${monk-volume-path}/airflow/dags:/opt/airflow/dags`
        - <- `${monk-volume-path}/airflow/logs:/opt/airflow/logs`
        - <- `${monk-volume-path}/airflow/plugins:/opt/airflow/plugins`
  files:
    airflow_init_script:
      container: airflow-init
      mode: 0755
      path: /opt/airflow/init.sh
      contents: <<< files/init.sh
